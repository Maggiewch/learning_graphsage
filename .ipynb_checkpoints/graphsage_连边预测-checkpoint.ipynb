{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'graphsage'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-0ec96ba25d36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgraphsage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgraphsage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregators\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMeanAggregator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'graphsage'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from graphsage.encoders import Encoder\n",
    "from graphsage.aggregators import MeanAggregator\n",
    "import numpy as np\n",
    "import time\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "from graphsage.encoders import Encoder\n",
    "from graphsage.aggregators import MeanAggregator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Simple supervised GraphSAGE model as well as examples running the model\n",
    "on the Cora and Pubmed datasets.\n",
    "\"\"\"\n",
    "class SupervisedGraphSage(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, enc):\n",
    "        super(SupervisedGraphSage, self).__init__()\n",
    "        self.enc = enc\n",
    "        self.xent = nn.CrossEntropyLoss()\n",
    "\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(num_classes, enc.embed_dim))\n",
    "        init.xavier_uniform(self.weight)\n",
    "\n",
    "    def forward(self, nodes):\n",
    "        embeds = self.enc(nodes)\n",
    "        scores = self.weight.mm(embeds)\n",
    "        return scores.t()\n",
    "\n",
    "    def loss(self, nodes, labels):\n",
    "        scores = self.forward(nodes)\n",
    "        return self.xent(scores, labels.squeeze())\n",
    "\n",
    "def load_cora():\n",
    "    num_nodes = 2708\n",
    "    num_feats = 1433\n",
    "    feat_data = np.zeros((num_nodes, num_feats))\n",
    "    labels = np.empty((num_nodes,1), dtype=np.int64)\n",
    "    node_map = {}\n",
    "    label_map = {}\n",
    "    with open(\"cora/cora.content\") as fp:\n",
    "        for i,line in enumerate(fp):\n",
    "            info = line.strip().split()\n",
    "            feat_data[i,:] = [float(info[i]) for i in range(1,len(info)-1)]\n",
    "            node_map[info[0]] = i\n",
    "            if not info[-1] in label_map:\n",
    "                label_map[info[-1]] = len(label_map)\n",
    "            labels[i] = label_map[info[-1]]\n",
    "\n",
    "    adj_lists = defaultdict(set)\n",
    "    with open(\"cora/cora.cites\") as fp:\n",
    "        for i,line in enumerate(fp):\n",
    "            info = line.strip().split()\n",
    "            paper1 = node_map[info[0]]\n",
    "            paper2 = node_map[info[1]]\n",
    "            adj_lists[paper1].add(paper2)\n",
    "            adj_lists[paper2].add(paper1)\n",
    "    return feat_data, labels, adj_lists, node_map\n",
    "\n",
    "def run_cora():\n",
    "    np.random.seed(1)\n",
    "    random.seed(1)\n",
    "    num_nodes = 2708\n",
    "    feat_data, labels, adj_lists = load_cora()\n",
    "    features = nn.Embedding(2708, 1433)\n",
    "    features.weight = nn.Parameter(torch.FloatTensor(feat_data), requires_grad=False)\n",
    "   # features.cuda()\n",
    "\n",
    "    agg1 = MeanAggregator(features, cuda=True)\n",
    "    enc1 = Encoder(features, 1433, 128, adj_lists, agg1, gcn=True, cuda=False)\n",
    "    agg2 = MeanAggregator(lambda nodes : enc1(nodes).t(), cuda=False)\n",
    "    enc2 = Encoder(lambda nodes : enc1(nodes).t(), enc1.embed_dim, 128, adj_lists, agg2,\n",
    "            base_model=enc1, gcn=True, cuda=False)\n",
    "    enc1.num_samples = 5\n",
    "    enc2.num_samples = 5\n",
    "\n",
    "    graphsage = SupervisedGraphSage(7, enc2)\n",
    "    #graphsage.cuda()\n",
    "    rand_indices = np.random.permutation(num_nodes)\n",
    "    test = rand_indices[:1000]\n",
    "    val = rand_indices[1000:1500]\n",
    "    train = list(rand_indices[1500:])\n",
    "\n",
    "    optimizer = torch.optim.SGD(filter(lambda p : p.requires_grad, graphsage.parameters()), lr=0.7)\n",
    "    times = []\n",
    "    for batch in range(100):\n",
    "        batch_nodes = train[:256]\n",
    "        random.shuffle(train)\n",
    "        start_time = time.time()\n",
    "        optimizer.zero_grad()\n",
    "        loss = graphsage.loss(batch_nodes, \n",
    "                Variable(torch.LongTensor(labels[np.array(batch_nodes)])))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        end_time = time.time()\n",
    "        times.append(end_time-start_time)\n",
    "        print (batch, loss.data[0])\n",
    "\n",
    "    val_output = graphsage.forward(val) \n",
    "    print (\"Validation F1:\", f1_score(labels[val], val_output.data.numpy().argmax(axis=1), average=\"micro\"))\n",
    "    print (\"Average batch time:\", np.mean(times))\n",
    "\n",
    "def load_pubmed():\n",
    "    #hardcoded for simplicity...\n",
    "    num_nodes = 19717\n",
    "    num_feats = 500\n",
    "    feat_data = np.zeros((num_nodes, num_feats))\n",
    "    labels = np.empty((num_nodes, 1), dtype=np.int64)\n",
    "    node_map = {}\n",
    "    with open(\"pubmed-data/Pubmed-Diabetes.NODE.paper.tab\") as fp:\n",
    "        fp.readline()\n",
    "        feat_map = {entry.split(\":\")[1]:i-1 for i,entry in enumerate(fp.readline().split(\"\\t\"))}\n",
    "        for i, line in enumerate(fp):\n",
    "            info = line.split(\"\\t\")\n",
    "            node_map[info[0]] = i\n",
    "            labels[i] = int(info[1].split(\"=\")[1])-1\n",
    "            for word_info in info[2:-1]:\n",
    "                word_info = word_info.split(\"=\")\n",
    "                feat_data[i][feat_map[word_info[0]]] = float(word_info[1])\n",
    "    adj_lists = defaultdict(set)\n",
    "    with open(\"pubmed-data/Pubmed-Diabetes.DIRECTED.cites.tab\") as fp:\n",
    "        fp.readline()\n",
    "        fp.readline()\n",
    "        for line in fp:\n",
    "            info = line.strip().split(\"\\t\")\n",
    "            paper1 = node_map[info[1].split(\":\")[1]]\n",
    "            paper2 = node_map[info[-1].split(\":\")[1]]\n",
    "            adj_lists[paper1].add(paper2)\n",
    "            adj_lists[paper2].add(paper1)\n",
    "    return feat_data, labels, adj_lists\n",
    "\n",
    "def run_pubmed():\n",
    "    np.random.seed(1)\n",
    "    random.seed(1)\n",
    "    num_nodes = 19717\n",
    "    feat_data, labels, adj_lists = load_pubmed()\n",
    "    features = nn.Embedding(19717, 500)\n",
    "    features.weight = nn.Parameter(torch.FloatTensor(feat_data), requires_grad=False)\n",
    "   # features.cuda()\n",
    "\n",
    "    agg1 = MeanAggregator(features, cuda=True)\n",
    "    enc1 = Encoder(features, 500, 128, adj_lists, agg1, gcn=True, cuda=False)\n",
    "    agg2 = MeanAggregator(lambda nodes : enc1(nodes).t(), cuda=False)\n",
    "    enc2 = Encoder(lambda nodes : enc1(nodes).t(), enc1.embed_dim, 128, adj_lists, agg2,\n",
    "            base_model=enc1, gcn=True, cuda=False)\n",
    "    enc1.num_samples = 10\n",
    "    enc2.num_samples = 25\n",
    "\n",
    "    graphsage = SupervisedGraphSage(3, enc2)\n",
    "    #graphsage.cuda()\n",
    "    rand_indices = np.random.permutation(num_nodes)\n",
    "    test = rand_indices[:1000]\n",
    "    val = rand_indices[1000:1500]\n",
    "    train = list(rand_indices[1500:])\n",
    "\n",
    "    optimizer = torch.optim.SGD(filter(lambda p : p.requires_grad, graphsage.parameters()), lr=0.7)\n",
    "    times = []\n",
    "    for batch in range(200):\n",
    "        batch_nodes = train[:1024]\n",
    "        random.shuffle(train)\n",
    "        start_time = time.time()\n",
    "        optimizer.zero_grad()\n",
    "        loss = graphsage.loss(batch_nodes, \n",
    "                Variable(torch.LongTensor(labels[np.array(batch_nodes)])))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        end_time = time.time()\n",
    "        times.append(end_time-start_time)\n",
    "        print (batch, loss.data[0])\n",
    "\n",
    "    val_output = graphsage.forward(val) \n",
    "    print (\"Validation F1:\", f1_score(labels[val], val_output.data.numpy().argmax(axis=1), average=\"micro\"))\n",
    "    print (\"Average batch time:\", np.mean(times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feat_data, labels, adj_lists, nodes_map = load_cora()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node_list = []\n",
    "source_list = []\n",
    "target_list = []\n",
    "for node in nodes_map:\n",
    "    node_list.append(nodes_map[node])\n",
    "    for end in adj_lists[nodes_map[node]]:\n",
    "        source_list.append(nodes_map[node])\n",
    "        target_list.append(end)\n",
    "data_nolink = []\n",
    "for node in nodes_map:\n",
    "    for in_node in node_list:\n",
    "        if in_node not in adj_lists[nodes_map[node]]:\n",
    "            data_nolink.append([nodes_map[node], in_node])\n",
    "data_link = np.array([source_list,target_list]).T            \n",
    "data_nolink = np.array(data_nolink)\n",
    "rand_indices = np.random.permutation(len(data_nolink))\n",
    "all_sample = np.vstack((data_link,data_nolink[rand_indices[:len(data_link)]]))\n",
    "\n",
    "#len(all_sample)\n",
    "\n",
    "linkprediction_label = []\n",
    "for i in range(len(all_sample)):\n",
    "    if i < len(data_link):\n",
    "        linkprediction_label.append([1])\n",
    "    else:\n",
    "        linkprediction_label.append([0])\n",
    "\n",
    "\n",
    "linkprediction_label = np.array(linkprediction_label)\n",
    "linkprediction_label_bcel = torch.FloatTensor(linkprediction_label)\n",
    "\n",
    "#all_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2540\n"
     ]
    }
   ],
   "source": [
    "adj_163 = list(adj_lists[163])\n",
    "no_adj_163 = []\n",
    "for node in node_list:\n",
    "    if node not in adj_163:\n",
    "        no_adj_163.append(node)\n",
    "print(len(no_adj_163))\n",
    "\n",
    "rand_index = np.random.permutation(len(no_adj_163))\n",
    "sample_no_adj = rand_index[:len(adj_163)]\n",
    "sample_index = copy.copy(adj_163)\n",
    "sample_index.extend(sample_no_adj)\n",
    "sample_rand_index = np.array([sample_index[i] for i in np.random.permutation(len(sample_index))])\n",
    "\n",
    "labels_163 = []\n",
    "for node in node_list :\n",
    "    if node in adj_163:\n",
    "        labels_163.append(1)\n",
    "    else:\n",
    "        labels_163.append(0)\n",
    "        \n",
    "all_sample_163 = copy.copy(adj_163)\n",
    "all_sample_163.extend(no_adj_163)\n",
    "\n",
    "node_prediction_163 = []\n",
    "for la in labels_163:\n",
    "    node_prediction_163.append([la])\n",
    "\n",
    "node_prediction_163 = np.array(node_prediction_163)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node_prediction_163_bcel = torch.FloatTensor(node_prediction_163)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 163号节点的预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SupervisedGraphSage(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, enc):\n",
    "        super(SupervisedGraphSage, self).__init__()\n",
    "        self.enc = enc\n",
    "        self.xent = nn.BCELoss()\n",
    "\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(num_classes, enc.embed_dim))\n",
    "        init.xavier_uniform(self.weight)\n",
    "\n",
    "    def forward(self, nodes1):\n",
    "        embeds1 = self.enc(nodes1)\n",
    "        #embeds2 = self.enc(nodes2)\n",
    "        print(embeds1.shape)\n",
    "        #print(embeds2.shape)\n",
    "        print(self.weight.shape)\n",
    "        #print ((embeds1*embeds2).shape)#inner directly\n",
    "        scores = self.weight.mm(embeds1)\n",
    "        #print(scores)\n",
    "        \n",
    "        return scores.t()\n",
    "\n",
    "    def loss(self, nodes1, labels):\n",
    "        scores = self.forward(nodes1)\n",
    "        scores = F.sigmoid(scores)\n",
    "        return self.xent(scores, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ae55a4635031>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnum_nodes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2708\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mfeat_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj_lists\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_cora\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2708\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1433\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "num_nodes = 2708\n",
    "feat_data, labels, adj_lists,_ = load_cora()\n",
    "features = nn.Embedding(2708, 1433)\n",
    "features.weight = nn.Parameter(torch.FloatTensor(feat_data), requires_grad=False)\n",
    "# features.cuda()\n",
    "\n",
    "agg1 = MeanAggregator(features, cuda=True)\n",
    "enc1 = Encoder(features, 1433, 128, adj_lists, agg1, gcn=True, cuda=False)\n",
    "agg2 = MeanAggregator(lambda nodes : enc1(nodes).t(), cuda=False)\n",
    "enc2 = Encoder(lambda nodes : enc1(nodes).t(), enc1.embed_dim, 1433, adj_lists, agg2,\n",
    "        base_model=enc1, gcn=True, cuda=False)\n",
    "enc1.num_samples = 5\n",
    "enc2.num_samples = 5\n",
    "#这里改一下输出的维度\n",
    "graphsage = SupervisedGraphSage(1, enc2)\n",
    "#graphsage.cuda()\n",
    "#rand_indices = np.random.permutation(len(node_list))\n",
    "test = sample_rand_index[:50]\n",
    "val = sample_rand_index[50:100]\n",
    "train = list(sample_rand_index[100:])\n",
    "\n",
    "optimizer = torch.optim.SGD(filter(lambda p : p.requires_grad, graphsage.parameters()), lr=0.5)\n",
    "times = []\n",
    "Loss = []\n",
    "for batch in range(200):\n",
    "    #batch_nodes1 = np.ones(100)*163#No.163\n",
    "    batch_nodes2 = train[:40]\n",
    "    batch_idx = copy.copy(train[:40])\n",
    "    random.shuffle(train)\n",
    "    start_time = time.time()\n",
    "    optimizer.zero_grad()\n",
    "    loss = graphsage.loss(batch_nodes2,\n",
    "            Variable(node_prediction_163_bcel[np.array(batch_idx)]))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    end_time = time.time()\n",
    "    times.append(end_time-start_time)\n",
    "    #print (batch, loss.data[0])\n",
    "    Loss.append(loss.data[0])\n",
    "val_output = graphsage.forward(val) \n",
    "#print (\"Validation F1:\", f1_score(node_prediction_163_bcel[val], val_output.data.numpy().argmax(axis=1), average=\"micro\"))\n",
    "#print (\"Average batch time:\", np.mean(times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0002], grad_fn=<AbsBackward>)\n",
      "tensor([0.9316], grad_fn=<AbsBackward>)\n",
      "tensor([0.0001], grad_fn=<AbsBackward>)\n",
      "tensor([0.0005], grad_fn=<AbsBackward>)\n",
      "tensor([0.0011], grad_fn=<AbsBackward>)\n",
      "tensor([0.0003], grad_fn=<AbsBackward>)\n",
      "tensor([0.0045], grad_fn=<AbsBackward>)\n",
      "tensor([0.0016], grad_fn=<AbsBackward>)\n",
      "tensor([0.0008], grad_fn=<AbsBackward>)\n",
      "tensor([0.0127], grad_fn=<AbsBackward>)\n",
      "tensor([0.0001], grad_fn=<AbsBackward>)\n",
      "tensor([0.0004], grad_fn=<AbsBackward>)\n",
      "tensor([0.0002], grad_fn=<AbsBackward>)\n",
      "tensor([0.0097], grad_fn=<AbsBackward>)\n",
      "tensor([0.0000], grad_fn=<AbsBackward>)\n",
      "tensor([0.0432], grad_fn=<AbsBackward>)\n",
      "tensor([0.0001], grad_fn=<AbsBackward>)\n",
      "tensor([0.3818], grad_fn=<AbsBackward>)\n",
      "tensor([0.0111], grad_fn=<AbsBackward>)\n",
      "tensor([0.1489], grad_fn=<AbsBackward>)\n",
      "tensor([0.0054], grad_fn=<AbsBackward>)\n",
      "tensor([0.0031], grad_fn=<AbsBackward>)\n",
      "tensor([0.5546], grad_fn=<AbsBackward>)\n",
      "tensor([0.0907], grad_fn=<AbsBackward>)\n",
      "tensor([0.0220], grad_fn=<AbsBackward>)\n",
      "tensor([0.0003], grad_fn=<AbsBackward>)\n",
      "tensor([0.0002], grad_fn=<AbsBackward>)\n",
      "tensor([0.0005], grad_fn=<AbsBackward>)\n",
      "tensor([0.0118], grad_fn=<AbsBackward>)\n",
      "tensor([0.0001], grad_fn=<AbsBackward>)\n",
      "tensor([0.0303], grad_fn=<AbsBackward>)\n",
      "tensor([0.0995], grad_fn=<AbsBackward>)\n",
      "tensor([0.0274], grad_fn=<AbsBackward>)\n",
      "tensor([0.1479], grad_fn=<AbsBackward>)\n",
      "tensor([0.0002], grad_fn=<AbsBackward>)\n",
      "tensor([0.0008], grad_fn=<AbsBackward>)\n",
      "tensor([0.0062], grad_fn=<AbsBackward>)\n",
      "tensor([0.0002], grad_fn=<AbsBackward>)\n",
      "tensor([0.1696], grad_fn=<AbsBackward>)\n",
      "tensor([0.0085], grad_fn=<AbsBackward>)\n",
      "tensor([0.0776], grad_fn=<AbsBackward>)\n",
      "tensor([0.0013], grad_fn=<AbsBackward>)\n",
      "tensor([0.0029], grad_fn=<AbsBackward>)\n",
      "tensor([0.6891], grad_fn=<AbsBackward>)\n",
      "tensor([0.0016], grad_fn=<AbsBackward>)\n",
      "tensor([0.0001], grad_fn=<AbsBackward>)\n",
      "tensor([0.0289], grad_fn=<AbsBackward>)\n",
      "tensor([0.1527], grad_fn=<AbsBackward>)\n",
      "tensor([5.3560e-06], grad_fn=<AbsBackward>)\n",
      "tensor([0.0007], grad_fn=<AbsBackward>)\n",
      "0.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    }
   ],
   "source": [
    "right = []\n",
    "wrong = []\n",
    "predict_list = F.sigmoid(val_output)\n",
    "for i in range(len(F.sigmoid(val_output))):\n",
    "    predict = predict_list[i]\n",
    "    target = node_prediction_163_bcel[val][i]\n",
    "    print(abs(predict - target))\n",
    "    if abs(predict - target)<0.5:\n",
    "        right.append(i)\n",
    "    else:\n",
    "        wrong.append(i)\n",
    "print(len(right)/(len(right)+len(wrong)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "node_list = []\n",
    "source_list = []\n",
    "target_list = []\n",
    "for node in nodes_map:\n",
    "    node_list.append(nodes_map[node])\n",
    "    for end in adj_lists[nodes_map[node]]:\n",
    "        source_list.append(nodes_map[node])\n",
    "        target_list.append(end)\n",
    "data_nolink = []\n",
    "for node in nodes_map:\n",
    "    for in_node in node_list:\n",
    "        if in_node not in adj_lists[nodes_map[node]]:\n",
    "            data_nolink.append([nodes_map[node], in_node])\n",
    "            \n",
    "data_nolink = np.array(data_nolink)\n",
    "rand_indices = np.random.permutation(len(data_nolink))\n",
    "all_sample = np.vstack((data_link,data_nolink[rand_indices[:len(data_link)]]))\n",
    "\n",
    "#len(all_sample)\n",
    "\n",
    "linkprediction_label = []\n",
    "for i in range(len(all_sample)):\n",
    "    if i < len(data_link):\n",
    "        linkprediction_label.append([1])\n",
    "    else:\n",
    "        linkprediction_label.append([0])\n",
    "\n",
    "\n",
    "linkprediction_label = np.array(linkprediction_label)\n",
    "#linkprediction_label\n",
    "\n",
    "#all_sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 节点对的连边预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SupervisedGraphSage(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, enc):\n",
    "        super(SupervisedGraphSage, self).__init__()\n",
    "        self.enc = enc\n",
    "        self.xent = nn.BCELoss()\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(num_classes, enc.embed_dim))\n",
    "        init.xavier_uniform(self.weight)\n",
    "\n",
    "    def forward(self, nodes1, nodes2):\n",
    "        embeds1 = self.enc(nodes1)\n",
    "        embeds2 = self.enc(nodes2)\n",
    "        print(embeds1.shape)\n",
    "        #print(embeds2.shape)\n",
    "        print(self.weight.shape)\n",
    "        #print ((embeds1*embeds2).shape)#inner directly\n",
    "        scores = (torch.ones((1,self.enc.embed_dim))).mm(embeds1*embeds2)\n",
    "        #print(scores)\n",
    "        \n",
    "        return scores.t()\n",
    "\n",
    "    def loss(self, nodes1, nodes2, labels):\n",
    "        scores = self.forward(nodes1,nodes2)\n",
    "        scores = F.sigmoid(scores)\n",
    "        return self.xent(scores, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/Desktop/算法/graphsage-simple-master/graphsage/encoders.py:31: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  init.xavier_uniform(self.weight)\n",
      "/Users/apple/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  \n",
      "/Users/apple/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/Users/apple/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n",
      "/Users/apple/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "0 tensor(0.7209)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "1 tensor(0.6731)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "2 tensor(0.7107)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "3 tensor(0.6907)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "4 tensor(0.7263)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "5 tensor(0.6693)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "6 tensor(0.7158)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "7 tensor(0.6894)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "8 tensor(0.6865)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "9 tensor(0.6805)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "10 tensor(0.7024)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "11 tensor(0.6770)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "12 tensor(0.6695)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "13 tensor(0.6936)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "14 tensor(0.6933)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "15 tensor(0.6752)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "16 tensor(0.6845)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "17 tensor(0.7166)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "18 tensor(0.6972)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "19 tensor(0.6822)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "20 tensor(0.6684)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "21 tensor(0.7211)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "22 tensor(0.6737)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "23 tensor(0.6711)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "24 tensor(0.6932)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "25 tensor(0.6971)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "26 tensor(0.7172)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "27 tensor(0.7264)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "28 tensor(0.6943)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "29 tensor(0.6754)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "30 tensor(0.7100)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "31 tensor(0.6593)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "32 tensor(0.6741)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "33 tensor(0.6691)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "34 tensor(0.6768)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "35 tensor(0.6893)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "36 tensor(0.6724)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "37 tensor(0.6893)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "38 tensor(0.6445)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "39 tensor(0.6959)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "40 tensor(0.6996)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "41 tensor(0.6648)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "42 tensor(0.6873)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "43 tensor(0.6709)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "44 tensor(0.6872)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "45 tensor(0.6674)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "46 tensor(0.6718)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "47 tensor(0.6852)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "48 tensor(0.6961)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "49 tensor(0.6701)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "50 tensor(0.6473)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "51 tensor(0.6907)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "52 tensor(0.6971)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "53 tensor(0.6411)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "54 tensor(0.7199)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "55 tensor(0.6557)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "56 tensor(0.6374)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "57 tensor(0.7103)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "58 tensor(0.7122)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "59 tensor(0.6642)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "60 tensor(0.7394)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "61 tensor(0.6672)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "62 tensor(0.6740)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "63 tensor(0.6992)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "64 tensor(0.6666)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "65 tensor(0.6942)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "66 tensor(0.6803)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "67 tensor(0.6955)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "68 tensor(0.6746)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "69 tensor(0.6735)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "70 tensor(0.6737)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "71 tensor(0.7188)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "72 tensor(0.7010)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "73 tensor(0.6688)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "74 tensor(0.6845)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "75 tensor(0.6927)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "76 tensor(0.7023)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "77 tensor(0.6601)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "78 tensor(0.6797)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "79 tensor(0.6673)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "80 tensor(0.6644)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "81 tensor(0.6849)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "82 tensor(0.7201)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "83 tensor(0.7172)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "84 tensor(0.7149)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "85 tensor(0.6421)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "86 tensor(0.6683)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "87 tensor(0.6557)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "88 tensor(0.6984)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "89 tensor(0.7037)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "90 tensor(0.6684)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "91 tensor(0.7227)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "92 tensor(0.6988)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "93 tensor(0.6929)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "94 tensor(0.6984)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "95 tensor(0.6919)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "96 tensor(0.6646)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "97 tensor(0.7193)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "98 tensor(0.6798)\n",
      "torch.Size([128, 32])\n",
      "torch.Size([1, 128])\n",
      "99 tensor(0.7125)\n",
      "torch.Size([128, 500])\n",
      "torch.Size([1, 128])\n",
      "Validation F1: 0.5\n",
      "Average batch time: 0.0206332039833\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "num_nodes = 2708\n",
    "feat_data, labels, adj_lists,_ = load_cora()\n",
    "features = nn.Embedding(2708, 1433)\n",
    "features.weight = nn.Parameter(torch.FloatTensor(feat_data), requires_grad=False)\n",
    "# features.cuda()\n",
    "\n",
    "agg1 = MeanAggregator(features, cuda=True)\n",
    "enc1 = Encoder(features, 1433, 128, adj_lists, agg1, gcn=True, cuda=False)\n",
    "agg2 = MeanAggregator(lambda nodes : enc1(nodes).t(), cuda=False)\n",
    "enc2 = Encoder(lambda nodes : enc1(nodes).t(), enc1.embed_dim, 128, adj_lists, agg2,\n",
    "        base_model=enc1, gcn=True, cuda=False)\n",
    "enc1.num_samples = 5\n",
    "enc2.num_samples = 5\n",
    "\n",
    "graphsage = SupervisedGraphSage(1, enc2)\n",
    "#graphsage.cuda()\n",
    "rand_indices = np.random.permutation(len(all_sample))\n",
    "test = rand_indices[:1000]\n",
    "val = rand_indices[1000:1500]\n",
    "train = list(rand_indices[1500:])\n",
    "\n",
    "optimizer = torch.optim.SGD(filter(lambda p : p.requires_grad, graphsage.parameters()), lr=0.01)\n",
    "times = []\n",
    "Loss = []\n",
    "for batch in range(100):\n",
    "    batch_nodes1 = all_sample[train[:32]][:,0]\n",
    "    batch_nodes2 = all_sample[train[:32]][:,1]\n",
    "    batch_idx = copy.copy(train[:32])\n",
    "    random.shuffle(train)\n",
    "    start_time = time.time()\n",
    "    optimizer.zero_grad()\n",
    "    loss = graphsage.loss(batch_nodes1, batch_nodes2,\n",
    "            Variable(linkprediction_label_bcel[np.array(batch_idx)]))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    end_time = time.time()\n",
    "    times.append(end_time-start_time)\n",
    "    print (batch, loss.data[0])\n",
    "    Loss.append(loss.data[0])\n",
    "val_output = graphsage.forward(all_sample[val][:,0],all_sample[val][:,1]) \n",
    "print (\"Validation F1:\", f1_score(linkprediction_label_bcel[val], val_output.data.numpy().argmax(axis=1), average=\"micro\"))\n",
    "print (\"Average batch time:\", np.mean(times))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 两个节点拼接，预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SupervisedGraphSage(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, enc):\n",
    "        super(SupervisedGraphSage, self).__init__()\n",
    "        self.enc = enc\n",
    "        self.xent = nn.BCELoss()\n",
    "\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(num_classes, enc.embed_dim*2))\n",
    "        init.xavier_uniform(self.weight)\n",
    "\n",
    "    def forward(self, nodes1, nodes2):\n",
    "        embeds1 = self.enc(nodes1)\n",
    "        embeds2 = self.enc(nodes2)\n",
    "        print(embeds1.shape)\n",
    "        #print(embeds2.shape)\n",
    "        print(self.weight.shape)\n",
    "        #print ((embeds1*embeds2).shape)#inner directly\n",
    "        combined = torch.cat([embeds1, embeds2], dim=0)\n",
    "        scores = self.weight.mm(combined)\n",
    "        #print(scores)\n",
    "        \n",
    "        return scores.t()\n",
    "\n",
    "    def loss(self, nodes1, nodes2, labels):\n",
    "        scores = self.forward(nodes1,nodes2)\n",
    "        scores = F.sigmoid(scores)\n",
    "        return self.xent(scores, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/Desktop/算法/graphsage-simple-master/graphsage/encoders.py:31: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  init.xavier_uniform(self.weight)\n",
      "/Users/apple/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  if __name__ == '__main__':\n",
      "/Users/apple/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:1006: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "/Users/apple/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:40: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "0 tensor(0.6907)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "1 tensor(0.6923)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "2 tensor(0.6950)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "3 tensor(0.6931)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "4 tensor(0.6946)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "5 tensor(0.6919)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "6 tensor(0.6926)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "7 tensor(0.6934)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "8 tensor(0.6918)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "9 tensor(0.6926)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "10 tensor(0.6922)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "11 tensor(0.6918)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "12 tensor(0.6932)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "13 tensor(0.6925)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "14 tensor(0.6912)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "15 tensor(0.6933)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "16 tensor(0.6914)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "17 tensor(0.6896)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "18 tensor(0.6891)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "19 tensor(0.6902)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "20 tensor(0.6910)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "21 tensor(0.6898)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "22 tensor(0.6921)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "23 tensor(0.6878)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "24 tensor(0.6915)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "25 tensor(0.6903)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "26 tensor(0.6876)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "27 tensor(0.6870)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "28 tensor(0.6901)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "29 tensor(0.6889)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "30 tensor(0.6882)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "31 tensor(0.6890)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "32 tensor(0.6859)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "33 tensor(0.6872)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "34 tensor(0.6897)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "35 tensor(0.6899)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "36 tensor(0.6910)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "37 tensor(0.6918)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "38 tensor(0.6897)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "39 tensor(0.6894)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "40 tensor(0.6892)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "41 tensor(0.6882)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "42 tensor(0.6867)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "43 tensor(0.6868)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "44 tensor(0.6872)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "45 tensor(0.6910)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "46 tensor(0.6867)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "47 tensor(0.6872)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "48 tensor(0.6876)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "49 tensor(0.6878)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "50 tensor(0.6860)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "51 tensor(0.6844)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "52 tensor(0.6863)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "53 tensor(0.6862)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "54 tensor(0.6856)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "55 tensor(0.6870)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "56 tensor(0.6885)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "57 tensor(0.6855)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "58 tensor(0.6829)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "59 tensor(0.6853)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "60 tensor(0.6860)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "61 tensor(0.6830)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "62 tensor(0.6845)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "63 tensor(0.6873)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "64 tensor(0.6859)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "65 tensor(0.6837)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "66 tensor(0.6868)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "67 tensor(0.6847)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "68 tensor(0.6855)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "69 tensor(0.6836)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "70 tensor(0.6902)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "71 tensor(0.6826)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "72 tensor(0.6873)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "73 tensor(0.6844)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "74 tensor(0.6829)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "75 tensor(0.6834)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "76 tensor(0.6882)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "77 tensor(0.6777)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "78 tensor(0.6811)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "79 tensor(0.6803)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "80 tensor(0.6807)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "81 tensor(0.6842)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "82 tensor(0.6773)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "83 tensor(0.6844)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "84 tensor(0.6740)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "85 tensor(0.6806)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "86 tensor(0.6827)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "87 tensor(0.6777)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "88 tensor(0.6841)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "89 tensor(0.6806)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "90 tensor(0.6747)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "91 tensor(0.6780)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "92 tensor(0.6897)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "93 tensor(0.6834)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "94 tensor(0.6753)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "95 tensor(0.6853)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "96 tensor(0.6800)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "97 tensor(0.6836)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "98 tensor(0.6843)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "99 tensor(0.6752)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "100 tensor(0.6848)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "101 tensor(0.6726)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "102 tensor(0.6650)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "103 tensor(0.6935)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "104 tensor(0.6739)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "105 tensor(0.6830)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "106 tensor(0.6710)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "107 tensor(0.6861)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "108 tensor(0.6668)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "109 tensor(0.6781)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "110 tensor(0.6687)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "111 tensor(0.6763)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "112 tensor(0.6853)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "113 tensor(0.6764)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "114 tensor(0.6840)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "115 tensor(0.6771)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "116 tensor(0.6814)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "117 tensor(0.6765)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "118 tensor(0.6878)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "119 tensor(0.6770)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "120 tensor(0.6846)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "121 tensor(0.6738)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "122 tensor(0.6910)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "123 tensor(0.6811)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "124 tensor(0.6835)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "125 tensor(0.6776)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "126 tensor(0.6762)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "127 tensor(0.6821)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "128 tensor(0.6749)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "129 tensor(0.6796)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "130 tensor(0.6759)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "131 tensor(0.6620)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "132 tensor(0.6893)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "133 tensor(0.6775)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "134 tensor(0.6693)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "135 tensor(0.6748)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "136 tensor(0.6859)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "137 tensor(0.6754)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "138 tensor(0.6804)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "139 tensor(0.6628)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "140 tensor(0.6682)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "141 tensor(0.6790)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "142 tensor(0.6669)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "143 tensor(0.6851)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "144 tensor(0.6727)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "145 tensor(0.6816)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "146 tensor(0.6760)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "147 tensor(0.6565)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "148 tensor(0.6675)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "149 tensor(0.6692)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "150 tensor(0.6724)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "151 tensor(0.6798)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "152 tensor(0.6814)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "153 tensor(0.6809)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "154 tensor(0.6844)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "155 tensor(0.6760)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "156 tensor(0.6879)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "157 tensor(0.6619)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "158 tensor(0.6815)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "159 tensor(0.6702)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "160 tensor(0.6709)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "161 tensor(0.6551)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "162 tensor(0.6674)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "163 tensor(0.6625)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "164 tensor(0.6800)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "165 tensor(0.6668)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "166 tensor(0.6705)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "167 tensor(0.6638)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "168 tensor(0.6508)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "169 tensor(0.6676)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "170 tensor(0.6676)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "171 tensor(0.6582)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "172 tensor(0.6655)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "173 tensor(0.6570)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "174 tensor(0.6722)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "175 tensor(0.6665)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "176 tensor(0.6694)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "177 tensor(0.6722)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "178 tensor(0.6476)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "179 tensor(0.6659)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "180 tensor(0.6838)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "181 tensor(0.6619)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "182 tensor(0.6660)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "183 tensor(0.6552)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "184 tensor(0.6472)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "185 tensor(0.6741)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "186 tensor(0.6579)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "187 tensor(0.6786)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "188 tensor(0.6706)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "189 tensor(0.6560)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "190 tensor(0.6665)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "191 tensor(0.6473)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "192 tensor(0.6529)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "193 tensor(0.6695)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "194 tensor(0.6431)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "195 tensor(0.6666)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "196 tensor(0.6545)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "197 tensor(0.6582)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "198 tensor(0.6475)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "199 tensor(0.6566)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "200 tensor(0.6534)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "201 tensor(0.6701)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "202 tensor(0.6654)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "203 tensor(0.6522)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "204 tensor(0.6720)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "205 tensor(0.6551)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "206 tensor(0.6576)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "207 tensor(0.6526)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "208 tensor(0.6561)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "209 tensor(0.6430)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "210 tensor(0.6742)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "211 tensor(0.6506)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "212 tensor(0.6663)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "213 tensor(0.6707)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "214 tensor(0.6632)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "215 tensor(0.6694)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "216 tensor(0.6499)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "217 tensor(0.6490)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "218 tensor(0.6410)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "219 tensor(0.6536)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "220 tensor(0.6504)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "221 tensor(0.6575)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "222 tensor(0.6573)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "223 tensor(0.6353)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "224 tensor(0.6710)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "225 tensor(0.7040)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "226 tensor(0.6822)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "227 tensor(0.6776)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "228 tensor(0.6480)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "229 tensor(0.6417)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "230 tensor(0.6423)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "231 tensor(0.6341)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "232 tensor(0.6456)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "233 tensor(0.6271)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "234 tensor(0.6555)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "235 tensor(0.6347)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "236 tensor(0.6444)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "237 tensor(0.6288)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "238 tensor(0.6593)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "239 tensor(0.6779)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "240 tensor(0.6446)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "241 tensor(0.6698)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "242 tensor(0.6335)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "243 tensor(0.6952)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "244 tensor(0.6771)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "245 tensor(0.6997)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "246 tensor(0.7053)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "247 tensor(0.6405)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "248 tensor(0.6621)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "249 tensor(0.6342)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "250 tensor(0.6773)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "251 tensor(0.6760)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "252 tensor(0.6792)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "253 tensor(0.6547)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "254 tensor(0.6575)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "255 tensor(0.6665)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "256 tensor(0.6722)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "257 tensor(0.6534)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "258 tensor(0.6625)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "259 tensor(0.6634)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "260 tensor(0.6614)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "261 tensor(0.6902)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "262 tensor(0.6475)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "263 tensor(0.6489)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "264 tensor(0.6447)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "265 tensor(0.6241)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "266 tensor(0.6724)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "267 tensor(0.6539)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "268 tensor(0.6778)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "269 tensor(0.6424)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "270 tensor(0.6523)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "271 tensor(0.6506)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "272 tensor(0.6659)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "273 tensor(0.6698)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "274 tensor(0.6564)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "275 tensor(0.6392)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "276 tensor(0.6575)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "277 tensor(0.6560)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "278 tensor(0.6586)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "279 tensor(0.6225)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "280 tensor(0.6488)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "281 tensor(0.6258)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "282 tensor(0.6468)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "283 tensor(0.6467)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "284 tensor(0.6198)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "285 tensor(0.6558)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "286 tensor(0.6215)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "287 tensor(0.6514)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "288 tensor(0.6449)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "289 tensor(0.6435)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "290 tensor(0.6326)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "291 tensor(0.6546)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "292 tensor(0.6558)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "293 tensor(0.6413)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "294 tensor(0.6739)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "295 tensor(0.6523)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "296 tensor(0.6315)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "297 tensor(0.6627)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "298 tensor(0.6416)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "299 tensor(0.6680)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "300 tensor(0.7004)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "301 tensor(0.6669)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "302 tensor(0.6465)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "303 tensor(0.6568)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "304 tensor(0.6509)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "305 tensor(0.6589)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "306 tensor(0.6560)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "307 tensor(0.6564)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "308 tensor(0.6525)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "309 tensor(0.6131)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "310 tensor(0.6560)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "311 tensor(0.6787)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "312 tensor(0.6380)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "313 tensor(0.6368)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "314 tensor(0.6507)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "315 tensor(0.6198)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "316 tensor(0.6457)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "317 tensor(0.6666)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "318 tensor(0.6453)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "319 tensor(0.6544)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "320 tensor(0.6691)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "321 tensor(0.6319)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "322 tensor(0.6499)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "323 tensor(0.6357)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "324 tensor(0.6316)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "325 tensor(0.6529)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "326 tensor(0.6382)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "327 tensor(0.6659)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "328 tensor(0.6270)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "329 tensor(0.6254)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "330 tensor(0.6379)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "331 tensor(0.6402)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "332 tensor(0.6612)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "333 tensor(0.6338)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "334 tensor(0.6293)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "335 tensor(0.6360)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "336 tensor(0.6444)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "337 tensor(0.6635)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "338 tensor(0.7127)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "339 tensor(0.6659)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "340 tensor(0.6722)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "341 tensor(0.6530)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "342 tensor(0.6447)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "343 tensor(0.6201)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "344 tensor(0.6482)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "345 tensor(0.6375)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "346 tensor(0.6518)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "347 tensor(0.6375)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "348 tensor(0.6248)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "349 tensor(0.6369)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "350 tensor(0.6302)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "351 tensor(0.6207)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "352 tensor(0.6582)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "353 tensor(0.7196)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "354 tensor(0.7064)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "355 tensor(0.6496)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "356 tensor(0.6483)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "357 tensor(0.6467)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "358 tensor(0.6318)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "359 tensor(0.6280)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "360 tensor(0.6355)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "361 tensor(0.6357)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "362 tensor(0.6588)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "363 tensor(0.6086)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "364 tensor(0.6592)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "365 tensor(0.6432)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "366 tensor(0.6137)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "367 tensor(0.6529)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "368 tensor(0.6613)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "369 tensor(0.6934)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "370 tensor(0.6352)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "371 tensor(0.6734)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "372 tensor(0.6444)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "373 tensor(0.6187)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "374 tensor(0.6423)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "375 tensor(0.6673)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "376 tensor(0.6345)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "377 tensor(0.6193)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "378 tensor(0.6117)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "379 tensor(0.6407)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "380 tensor(0.6288)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "381 tensor(0.6478)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "382 tensor(0.6245)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "383 tensor(0.6195)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "384 tensor(0.6372)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "385 tensor(0.6533)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "386 tensor(0.6459)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "387 tensor(0.6728)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "388 tensor(0.6339)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "389 tensor(0.6238)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "390 tensor(0.6372)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "391 tensor(0.6087)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "392 tensor(0.6605)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "393 tensor(0.6396)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "394 tensor(0.6606)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "395 tensor(0.6254)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "396 tensor(0.6370)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "397 tensor(0.6479)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "398 tensor(0.6513)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "399 tensor(0.6156)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "400 tensor(0.6501)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "401 tensor(0.6029)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "402 tensor(0.6083)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "403 tensor(0.6295)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "404 tensor(0.6444)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "405 tensor(0.6437)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "406 tensor(0.6547)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "407 tensor(0.6664)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "408 tensor(0.6727)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "409 tensor(0.6115)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "410 tensor(0.6155)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "411 tensor(0.6401)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "412 tensor(0.6498)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "413 tensor(0.6245)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "414 tensor(0.6298)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "415 tensor(0.6232)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "416 tensor(0.6341)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "417 tensor(0.6320)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "418 tensor(0.6241)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "419 tensor(0.6627)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "420 tensor(0.6912)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "421 tensor(0.6637)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "422 tensor(0.6198)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "423 tensor(0.6247)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "424 tensor(0.6468)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "425 tensor(0.6276)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "426 tensor(0.6163)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "427 tensor(0.6646)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "428 tensor(0.6434)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "429 tensor(0.6502)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "430 tensor(0.6292)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "431 tensor(0.6045)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "432 tensor(0.6048)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "433 tensor(0.6088)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "434 tensor(0.6568)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "435 tensor(0.6580)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "436 tensor(0.6083)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "437 tensor(0.6239)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "438 tensor(0.6666)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "439 tensor(0.6545)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "440 tensor(0.6600)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "441 tensor(0.6668)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "442 tensor(0.6823)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "443 tensor(0.6212)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "444 tensor(0.6134)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "445 tensor(0.6160)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "446 tensor(0.5954)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "447 tensor(0.6253)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "448 tensor(0.6349)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "449 tensor(0.6350)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "450 tensor(0.6670)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "451 tensor(0.7052)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "452 tensor(0.6605)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "453 tensor(0.6319)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "454 tensor(0.6176)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "455 tensor(0.6369)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "456 tensor(0.6688)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "457 tensor(0.6380)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "458 tensor(0.5987)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "459 tensor(0.6277)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "460 tensor(0.6052)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "461 tensor(0.6154)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "462 tensor(0.6364)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "463 tensor(0.6263)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "464 tensor(0.6445)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "465 tensor(0.6140)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "466 tensor(0.5899)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "467 tensor(0.6365)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "468 tensor(0.6490)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "469 tensor(0.6070)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "470 tensor(0.6151)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "471 tensor(0.6155)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "472 tensor(0.6225)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "473 tensor(0.6178)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "474 tensor(0.6436)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "475 tensor(0.6644)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "476 tensor(0.6153)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "477 tensor(0.6143)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "478 tensor(0.6113)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "479 tensor(0.5995)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "480 tensor(0.6260)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "481 tensor(0.6503)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "482 tensor(0.6517)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "483 tensor(0.6806)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "484 tensor(0.6708)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "485 tensor(0.6288)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "486 tensor(0.6386)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "487 tensor(0.6275)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "488 tensor(0.6068)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "489 tensor(0.6151)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "490 tensor(0.6343)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "491 tensor(0.6180)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "492 tensor(0.6244)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "493 tensor(0.6471)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "494 tensor(0.6274)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "495 tensor(0.6561)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "496 tensor(0.6118)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "497 tensor(0.6095)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "498 tensor(0.6209)\n",
      "torch.Size([128, 256])\n",
      "torch.Size([1, 256])\n",
      "499 tensor(0.6228)\n",
      "torch.Size([128, 500])\n",
      "torch.Size([1, 256])\n",
      "Validation F1: 0.5\n",
      "Average batch time: 0.171624484539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apple/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:41: UserWarning: invalid index of a 0-dim tensor. This will be an error in PyTorch 0.5. Use tensor.item() to convert a 0-dim tensor to a Python number\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "random.seed(1)\n",
    "num_nodes = 2708\n",
    "feat_data, labels, adj_lists,_ = load_cora()\n",
    "features = nn.Embedding(2708, 1433)\n",
    "features.weight = nn.Parameter(torch.FloatTensor(feat_data), requires_grad=False)\n",
    "# features.cuda()\n",
    "\n",
    "agg1 = MeanAggregator(features, cuda=True)\n",
    "enc1 = Encoder(features, 1433, 128, adj_lists, agg1, gcn=True, cuda=False)\n",
    "agg2 = MeanAggregator(lambda nodes : enc1(nodes).t(), cuda=False)\n",
    "enc2 = Encoder(lambda nodes : enc1(nodes).t(), enc1.embed_dim, 128, adj_lists, agg2,\n",
    "        base_model=enc1, gcn=True, cuda=False)\n",
    "enc1.num_samples = 5\n",
    "enc2.num_samples = 5\n",
    "\n",
    "graphsage = SupervisedGraphSage(1, enc2)\n",
    "#graphsage.cuda()\n",
    "rand_indices = np.random.permutation(len(all_sample))\n",
    "test = rand_indices[:1000]\n",
    "val = rand_indices[1000:1500]\n",
    "train = list(rand_indices[1500:])\n",
    "\n",
    "optimizer = torch.optim.SGD(filter(lambda p : p.requires_grad, graphsage.parameters()), lr=0.5)\n",
    "times = []\n",
    "Loss = []\n",
    "for batch in range(500):\n",
    "    batch_nodes1 = all_sample[train[:256]][:,0]\n",
    "    batch_nodes2 = all_sample[train[:256]][:,1]\n",
    "    batch_idx = copy.copy(train[:256])\n",
    "    random.shuffle(train)\n",
    "    start_time = time.time()\n",
    "    optimizer.zero_grad()\n",
    "    loss = graphsage.loss(batch_nodes1, batch_nodes2,\n",
    "            Variable(linkprediction_label_bcel[np.array(batch_idx)]))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    end_time = time.time()\n",
    "    times.append(end_time-start_time)\n",
    "    print (batch, loss.data[0])\n",
    "    Loss.append(loss.data[0])\n",
    "val_output = graphsage.forward(all_sample[val][:,0],all_sample[val][:,1]) \n",
    "print (\"Validation F1:\", f1_score(linkprediction_label_bcel[val], val_output.data.numpy().argmax(axis=1), average=\"micro\"))\n",
    "print (\"Average batch time:\", np.mean(times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEKCAYAAADjDHn2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1028bb470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(Loss)\n",
    "plt.xlabel('batches')\n",
    "plt.ylabel('loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "right = []\n",
    "wrong = []\n",
    "predict_list = F.sigmoid(val_output)\n",
    "for i in range(len(F.sigmoid(val_output))):\n",
    "    predict = predict_list[i]\n",
    "    target = linkprediction_label_bcel[val][i]\n",
    "    print(abs(predict - target))\n",
    "    if abs(predict - target)<0.5:\n",
    "        right.append(i)\n",
    "    else:\n",
    "        wrong.append(i)\n",
    "print(len(right)/(len(right)+len(wrong)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
